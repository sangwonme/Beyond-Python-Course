[
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "BertTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "BertModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "BertTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "BertModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "isExtraImport": true,
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "isExtraImport": true,
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "make_blobs",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "display_library",
        "kind": 2,
        "importPath": "CH1-UI-Design.quiz.library",
        "description": "CH1-UI-Design.quiz.library",
        "peekOfCode": "def display_library():\n    print(st.session_state['library'])\nwith st.form(\"Library Form\"):\n    title = st.text_input(\"Title\")\n    author = st.text_input(\"Author\")\n    year = st.number_input(\"Year\", min_value=1000, max_value=9999, step=1, format=\"%d\")\n    submit_button = st.form_submit_button(\"Submit\")\n    if submit_button:\n        pass\n        # TODO: call add_book",
        "detail": "CH1-UI-Design.quiz.library",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 5,
        "importPath": "CH1-UI-Design.quiz.library",
        "description": "CH1-UI-Design.quiz.library",
        "peekOfCode": "search = st.text_input(\"Search Book by Title\")\nif st.button(\"Search\"):\n    pass\n    # TODO: call search_book()\nremove = st.text_input(\"Remove Book by Title\")\nif st.button(\"Remove Book\"):\n    pass\n    # TODO: remove_book()",
        "detail": "CH1-UI-Design.quiz.library",
        "documentation": {}
    },
    {
        "label": "remove",
        "kind": 5,
        "importPath": "CH1-UI-Design.quiz.library",
        "description": "CH1-UI-Design.quiz.library",
        "peekOfCode": "remove = st.text_input(\"Remove Book by Title\")\nif st.button(\"Remove Book\"):\n    pass\n    # TODO: remove_book()",
        "detail": "CH1-UI-Design.quiz.library",
        "documentation": {}
    },
    {
        "label": "exchange_rates",
        "kind": 5,
        "importPath": "CH1-UI-Design.quiz.wallet",
        "description": "CH1-UI-Design.quiz.wallet",
        "peekOfCode": "exchange_rates = {\n    'USD': {'EUR': 0.95, 'GBP': 0.82, 'JPY': 140.5, 'USD': 1, 'KRW': 1300},\n    'EUR': {'USD': 1.05, 'GBP': 0.86, 'JPY': 147.9, 'EUR': 1, 'KRW': 1365},\n    'GBP': {'USD': 1.22, 'EUR': 1.16, 'JPY': 171.8, 'GBP': 1, 'KRW': 1583},\n    'JPY': {'USD': 0.0071, 'EUR': 0.0068, 'GBP': 0.0058, 'JPY': 1, 'KRW': 9.2},\n    'KRW': {'USD': 0.00077, 'EUR': 0.00073, 'GBP': 0.00063, 'JPY': 0.11, 'KRW': 1}\n}\n# Initialize wallet in session state if it does not exist\nif 'wallet' not in st.session_state:\n    st.session_state['wallet'] = {currency: 0 for currency in exchange_rates}",
        "detail": "CH1-UI-Design.quiz.wallet",
        "documentation": {}
    },
    {
        "label": "operation",
        "kind": 5,
        "importPath": "CH1-UI-Design.quiz.wallet",
        "description": "CH1-UI-Design.quiz.wallet",
        "peekOfCode": "operation = st.selectbox(\"Choose Operation\", (\"deposit\", \"withdraw\", \"exchange\"))\namount = st.number_input(\"Amount\", min_value=0.0, format=\"%f\")\ncurrency = st.selectbox(\"Currency\", options=list(exchange_rates.keys()))\nif operation == \"exchange\":\n    target_currency = st.selectbox(\"Target Currency\", options=list(exchange_rates.keys()))\n    if st.button(\"Execute Exchange\"):\n        pass\n        # TODO\nelse:\n    if st.button(f\"{operation.title()} {amount} {currency}\"):",
        "detail": "CH1-UI-Design.quiz.wallet",
        "documentation": {}
    },
    {
        "label": "amount",
        "kind": 5,
        "importPath": "CH1-UI-Design.quiz.wallet",
        "description": "CH1-UI-Design.quiz.wallet",
        "peekOfCode": "amount = st.number_input(\"Amount\", min_value=0.0, format=\"%f\")\ncurrency = st.selectbox(\"Currency\", options=list(exchange_rates.keys()))\nif operation == \"exchange\":\n    target_currency = st.selectbox(\"Target Currency\", options=list(exchange_rates.keys()))\n    if st.button(\"Execute Exchange\"):\n        pass\n        # TODO\nelse:\n    if st.button(f\"{operation.title()} {amount} {currency}\"):\n        if operation == \"deposit\":",
        "detail": "CH1-UI-Design.quiz.wallet",
        "documentation": {}
    },
    {
        "label": "currency",
        "kind": 5,
        "importPath": "CH1-UI-Design.quiz.wallet",
        "description": "CH1-UI-Design.quiz.wallet",
        "peekOfCode": "currency = st.selectbox(\"Currency\", options=list(exchange_rates.keys()))\nif operation == \"exchange\":\n    target_currency = st.selectbox(\"Target Currency\", options=list(exchange_rates.keys()))\n    if st.button(\"Execute Exchange\"):\n        pass\n        # TODO\nelse:\n    if st.button(f\"{operation.title()} {amount} {currency}\"):\n        if operation == \"deposit\":\n            pass",
        "detail": "CH1-UI-Design.quiz.wallet",
        "documentation": {}
    },
    {
        "label": "agree",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "agree = st.checkbox('I agree')\nif agree:\n    st.write('Great!')\n# # Toggle\ncctv = st.toggle('CCTV')\ntv = st.toggle('TV')\nac = st.toggle('AC')\nlight = st.toggle('LIGHT')\nst.write('Switch ON: ')\nif cctv:",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "cctv",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "cctv = st.toggle('CCTV')\ntv = st.toggle('TV')\nac = st.toggle('AC')\nlight = st.toggle('LIGHT')\nst.write('Switch ON: ')\nif cctv:\n    st.write('CCTV is on')\nif tv:\n    st.write('TV is on')\nif ac:",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "tv",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "tv = st.toggle('TV')\nac = st.toggle('AC')\nlight = st.toggle('LIGHT')\nst.write('Switch ON: ')\nif cctv:\n    st.write('CCTV is on')\nif tv:\n    st.write('TV is on')\nif ac:\n    st.write('AC is on')",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "ac",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "ac = st.toggle('AC')\nlight = st.toggle('LIGHT')\nst.write('Switch ON: ')\nif cctv:\n    st.write('CCTV is on')\nif tv:\n    st.write('TV is on')\nif ac:\n    st.write('AC is on')\nif light:",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "light",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "light = st.toggle('LIGHT')\nst.write('Switch ON: ')\nif cctv:\n    st.write('CCTV is on')\nif tv:\n    st.write('TV is on')\nif ac:\n    st.write('AC is on')\nif light:\n    st.write('LIGHT is on')",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "option",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "option = st.selectbox(\n    'How would you like to be contacted?',\n    ['Email', 'Home phone', 'Mobile phone'])\nst.write('You selected:', option)\n# # Multiselect\nprice = {\n    'apple': 30,\n    'banana': 20,\n    'grape': 50\n}",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "price",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "price = {\n    'apple': 30,\n    'banana': 20,\n    'grape': 50\n}\noptions = st.multiselect(\n    'What fruits do you want to buy?',\n    ['apple', 'banana', 'grape'],\n)\ntotal = 0",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "options",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "options = st.multiselect(\n    'What fruits do you want to buy?',\n    ['apple', 'banana', 'grape'],\n)\ntotal = 0\nfor fruit in options:\n    total += price[fruit]\nst.write('Price: ', total)\n# Slider\nage = st.slider('How old are you?', 0, 130, 25)",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "total",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "total = 0\nfor fruit in options:\n    total += price[fruit]\nst.write('Price: ', total)\n# Slider\nage = st.slider('How old are you?', 0, 130, 25)\nst.write(\"I'm \", age, 'years old')\n# Text Input\ntitle = st.text_input('Movie title', 'Life of Brian')\nst.write('The current movie title is', title)",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "age",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "age = st.slider('How old are you?', 0, 130, 25)\nst.write(\"I'm \", age, 'years old')\n# Text Input\ntitle = st.text_input('Movie title', 'Life of Brian')\nst.write('The current movie title is', title)\n# Number Input\nnumber = st.number_input('Insert a number')\nst.write('The current number is ', number)",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "title",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "title = st.text_input('Movie title', 'Life of Brian')\nst.write('The current movie title is', title)\n# Number Input\nnumber = st.number_input('Insert a number')\nst.write('The current number is ', number)",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "number",
        "kind": 5,
        "importPath": "CH1-UI-Design.streamlit-basic.tv",
        "description": "CH1-UI-Design.streamlit-basic.tv",
        "peekOfCode": "number = st.number_input('Insert a number')\nst.write('The current number is ', number)",
        "detail": "CH1-UI-Design.streamlit-basic.tv",
        "documentation": {}
    },
    {
        "label": "width",
        "kind": 5,
        "importPath": "CH3-API.api-basic.lorempicsum",
        "description": "CH3-API.api-basic.lorempicsum",
        "peekOfCode": "width = st.sidebar.number_input(\"Width\", min_value=100, max_value=1920, value=500)\nheight = st.sidebar.number_input(\"Height\", min_value=100, max_value=1080, value=500)\ngrayscale = st.sidebar.checkbox(\"Grayscale\")\nblur = st.sidebar.checkbox(\"Blur\")\n# Constructing the API URL based on user input\n# TODO: update_url\n# Fetching and displaying the image\nif st.sidebar.button(\"Fetch Image\"):\n    # TODO\n    response = requests.get(st.session_state['url'])",
        "detail": "CH3-API.api-basic.lorempicsum",
        "documentation": {}
    },
    {
        "label": "height",
        "kind": 5,
        "importPath": "CH3-API.api-basic.lorempicsum",
        "description": "CH3-API.api-basic.lorempicsum",
        "peekOfCode": "height = st.sidebar.number_input(\"Height\", min_value=100, max_value=1080, value=500)\ngrayscale = st.sidebar.checkbox(\"Grayscale\")\nblur = st.sidebar.checkbox(\"Blur\")\n# Constructing the API URL based on user input\n# TODO: update_url\n# Fetching and displaying the image\nif st.sidebar.button(\"Fetch Image\"):\n    # TODO\n    response = requests.get(st.session_state['url'])\n    if response.status_code == 200:",
        "detail": "CH3-API.api-basic.lorempicsum",
        "documentation": {}
    },
    {
        "label": "grayscale",
        "kind": 5,
        "importPath": "CH3-API.api-basic.lorempicsum",
        "description": "CH3-API.api-basic.lorempicsum",
        "peekOfCode": "grayscale = st.sidebar.checkbox(\"Grayscale\")\nblur = st.sidebar.checkbox(\"Blur\")\n# Constructing the API URL based on user input\n# TODO: update_url\n# Fetching and displaying the image\nif st.sidebar.button(\"Fetch Image\"):\n    # TODO\n    response = requests.get(st.session_state['url'])\n    if response.status_code == 200:\n        image = Image.open(BytesIO(response.content))",
        "detail": "CH3-API.api-basic.lorempicsum",
        "documentation": {}
    },
    {
        "label": "blur",
        "kind": 5,
        "importPath": "CH3-API.api-basic.lorempicsum",
        "description": "CH3-API.api-basic.lorempicsum",
        "peekOfCode": "blur = st.sidebar.checkbox(\"Blur\")\n# Constructing the API URL based on user input\n# TODO: update_url\n# Fetching and displaying the image\nif st.sidebar.button(\"Fetch Image\"):\n    # TODO\n    response = requests.get(st.session_state['url'])\n    if response.status_code == 200:\n        image = Image.open(BytesIO(response.content))\n        st.image(image, caption=\"Random Image from Lorem Picsum\")",
        "detail": "CH3-API.api-basic.lorempicsum",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "def cosine_similarity(vec1, vec2):\n    dot_product = np.dot(vec1, vec2)\n    norm_vec1 = np.linalg.norm(vec1)\n    norm_vec2 = np.linalg.norm(vec2)\n    return dot_product / (norm_vec1 * norm_vec2)\n# CLIP 모델 불러오기\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage = Image.open('./cat.jpg')",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage = Image.open('./cat.jpg')\n# 이미지 임베딩하기\nimage_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "processor",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage = Image.open('./cat.jpg')\n# 이미지 임베딩하기\nimage_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "image",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "image = Image.open('./cat.jpg')\n# 이미지 임베딩하기\nimage_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기\ntext_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "image_inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "image_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기\ntext_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 각 텍스트의 코사인 유사도 계산",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "texts",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "texts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기\ntext_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 각 텍스트의 코사인 유사도 계산\nprint('=======================================')\nfor i in range(len(texts)):\n    similarity = cosine_similarity(image_embedding[0], text_embedding[i])\n    print(texts[i], ' : ', similarity)",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "text_inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.1_clip_example",
        "description": "CH7-AI-Algorithms.clip.1_clip_example",
        "peekOfCode": "text_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 각 텍스트의 코사인 유사도 계산\nprint('=======================================')\nfor i in range(len(texts)):\n    similarity = cosine_similarity(image_embedding[0], text_embedding[i])\n    print(texts[i], ' : ', similarity)\nprint('=======================================')",
        "detail": "CH7-AI-Algorithms.clip.1_clip_example",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "description": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "peekOfCode": "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage = Image.open('./cat.jpg')\n# 이미지 임베딩하기\nimage_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']",
        "detail": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "documentation": {}
    },
    {
        "label": "processor",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "description": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "peekOfCode": "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage = Image.open('./cat.jpg')\n# 이미지 임베딩하기\nimage_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기",
        "detail": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "documentation": {}
    },
    {
        "label": "image",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "description": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "peekOfCode": "image = Image.open('./cat.jpg')\n# 이미지 임베딩하기\nimage_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기\ntext_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():",
        "detail": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "documentation": {}
    },
    {
        "label": "image_inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "description": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "peekOfCode": "image_inputs = processor(images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embedding = model.get_image_features(**image_inputs)\n# 텍스트 정의\ntexts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기\ntext_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 각 텍스트의 코사인 유사도 계산",
        "detail": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "documentation": {}
    },
    {
        "label": "texts",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "description": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "peekOfCode": "texts = ['A dog', 'A cat', 'A nuclear submarine']\n# 각 텍스트 임베딩하기\ntext_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 각 텍스트의 코사인 유사도 계산\nprint('=======================================')\nfor i in range(len(texts)):\n    similarity = cosine_similarity(image_embedding[0], text_embedding[i])\n    print(texts[i], ' : ', similarity)",
        "detail": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "documentation": {}
    },
    {
        "label": "text_inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "description": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "peekOfCode": "text_inputs = processor(text=texts, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 각 텍스트의 코사인 유사도 계산\nprint('=======================================')\nfor i in range(len(texts)):\n    similarity = cosine_similarity(image_embedding[0], text_embedding[i])\n    print(texts[i], ' : ', similarity)\nprint('=======================================')",
        "detail": "CH7-AI-Algorithms.clip.2_cosine_similarity",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimages = []\nimage_filenames = []\nfor i in range(9):\n    image_filenames.append('./topk-image/dog_'+str(i)+'.png')\n    images.append(Image.open(image_filenames[i]))\n# 이미지 임베딩\nimage_inputs = processor(images=images, return_tensors=\"pt\", padding=True)",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "processor",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimages = []\nimage_filenames = []\nfor i in range(9):\n    image_filenames.append('./topk-image/dog_'+str(i)+'.png')\n    images.append(Image.open(image_filenames[i]))\n# 이미지 임베딩\nimage_inputs = processor(images=images, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "images",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "images = []\nimage_filenames = []\nfor i in range(9):\n    image_filenames.append('./topk-image/dog_'+str(i)+'.png')\n    images.append(Image.open(image_filenames[i]))\n# 이미지 임베딩\nimage_inputs = processor(images=images, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embeddings = model.get_image_features(**image_inputs)\n# 텍스트",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "image_filenames",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "image_filenames = []\nfor i in range(9):\n    image_filenames.append('./topk-image/dog_'+str(i)+'.png')\n    images.append(Image.open(image_filenames[i]))\n# 이미지 임베딩\nimage_inputs = processor(images=images, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embeddings = model.get_image_features(**image_inputs)\n# 텍스트\ntext = ['A dog is sleeping']",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "image_inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "image_inputs = processor(images=images, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    image_embeddings = model.get_image_features(**image_inputs)\n# 텍스트\ntext = ['A dog is sleeping']\ntext_inputs = processor(text=text, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 코사인 유사도\nsimilarities = cosine_similarity(text_embedding, image_embeddings)",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "text",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "text = ['A dog is sleeping']\ntext_inputs = processor(text=text, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 코사인 유사도\nsimilarities = cosine_similarity(text_embedding, image_embeddings)\n# TOP-K 결과 찾기\nk = 3\ntop_3_indices = similarities.topk(k).indices\nprint(\"Top 3 most similar images:\")",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "text_inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "text_inputs = processor(text=text, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    text_embedding = model.get_text_features(**text_inputs)\n# 코사인 유사도\nsimilarities = cosine_similarity(text_embedding, image_embeddings)\n# TOP-K 결과 찾기\nk = 3\ntop_3_indices = similarities.topk(k).indices\nprint(\"Top 3 most similar images:\")\nfor idx in top_3_indices:",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "similarities",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "similarities = cosine_similarity(text_embedding, image_embeddings)\n# TOP-K 결과 찾기\nk = 3\ntop_3_indices = similarities.topk(k).indices\nprint(\"Top 3 most similar images:\")\nfor idx in top_3_indices:\n    print(f\"- {image_filenames[idx]}\")",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "k",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "k = 3\ntop_3_indices = similarities.topk(k).indices\nprint(\"Top 3 most similar images:\")\nfor idx in top_3_indices:\n    print(f\"- {image_filenames[idx]}\")",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "top_3_indices",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.3_topk_image",
        "description": "CH7-AI-Algorithms.clip.3_topk_image",
        "peekOfCode": "top_3_indices = similarities.topk(k).indices\nprint(\"Top 3 most similar images:\")\nfor idx in top_3_indices:\n    print(f\"- {image_filenames[idx]}\")",
        "detail": "CH7-AI-Algorithms.clip.3_topk_image",
        "documentation": {}
    },
    {
        "label": "search_image_by_text",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "def search_image_by_text(text_prompt):\n    # 텍스트 임베딩\n    # TODO: 퀴즈 5 - 여기에 코드를 작성하시오.\n    print(f'Text Embedding\\'s shape: {text_embedding.shape}')\n    # 코사인 유사도\n    similarities = cosine_similarity(text_embedding, image_embeddings)\n    print('-----------------------------------------------------')\n    print(\"The most similar image found is: \", end='')\n    # TODO: 퀴즈 6 - 여기에 코드를 작성하시오.\n# -------------------------------------------------",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "text_embedding",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "text_embedding = torch.zeros(0)\nimage_embeddings = torch.zeros(0)\n# CLIP 모델 불러오기\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage_filenames = [] # 이미지 파일 경로 200개를 저장\nimages = [] # 이미지 객체 200개를 저장\nfor i in range(200):\n    pass",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "image_embeddings",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "image_embeddings = torch.zeros(0)\n# CLIP 모델 불러오기\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage_filenames = [] # 이미지 파일 경로 200개를 저장\nimages = [] # 이미지 객체 200개를 저장\nfor i in range(200):\n    pass\n    # 이미지 파일 경로를 파악하여 image_filenames 생성",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage_filenames = [] # 이미지 파일 경로 200개를 저장\nimages = [] # 이미지 객체 200개를 저장\nfor i in range(200):\n    pass\n    # 이미지 파일 경로를 파악하여 image_filenames 생성\n    # TODO: 퀴즈 3 - 여기에 코드를 작성하시오.\nfor i in range(len(image_filenames)):",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "processor",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n# 이미지 불러오기\nimage_filenames = [] # 이미지 파일 경로 200개를 저장\nimages = [] # 이미지 객체 200개를 저장\nfor i in range(200):\n    pass\n    # 이미지 파일 경로를 파악하여 image_filenames 생성\n    # TODO: 퀴즈 3 - 여기에 코드를 작성하시오.\nfor i in range(len(image_filenames)):\n    image = Image.open(image_filenames[i])",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "image_filenames",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "image_filenames = [] # 이미지 파일 경로 200개를 저장\nimages = [] # 이미지 객체 200개를 저장\nfor i in range(200):\n    pass\n    # 이미지 파일 경로를 파악하여 image_filenames 생성\n    # TODO: 퀴즈 3 - 여기에 코드를 작성하시오.\nfor i in range(len(image_filenames)):\n    image = Image.open(image_filenames[i])\n    images.append(image)\nprint(f'Total {len(images)} images are loaded!')",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "images",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.clip.quiz_search",
        "description": "CH7-AI-Algorithms.clip.quiz_search",
        "peekOfCode": "images = [] # 이미지 객체 200개를 저장\nfor i in range(200):\n    pass\n    # 이미지 파일 경로를 파악하여 image_filenames 생성\n    # TODO: 퀴즈 3 - 여기에 코드를 작성하시오.\nfor i in range(len(image_filenames)):\n    image = Image.open(image_filenames[i])\n    images.append(image)\nprint(f'Total {len(images)} images are loaded!')\n# 이미지 임베딩",
        "detail": "CH7-AI-Algorithms.clip.quiz_search",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.embedding",
        "description": "CH7-AI-Algorithms.embedding-vector.embedding",
        "peekOfCode": "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n# 문장 정의\nsentence = \"I love reading books.\"\n# 문장을 토큰으로 변환 및 BERT 입력 형식으로 변환\ninputs = tokenizer(sentence, return_tensors='pt')\n# BERT 모델을 통해 임베딩 벡터 얻기\nwith torch.no_grad():\n    outputs = model(**inputs)\n# 임베딩 벡터 추출",
        "detail": "CH7-AI-Algorithms.embedding-vector.embedding",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.embedding",
        "description": "CH7-AI-Algorithms.embedding-vector.embedding",
        "peekOfCode": "model = BertModel.from_pretrained('bert-base-uncased')\n# 문장 정의\nsentence = \"I love reading books.\"\n# 문장을 토큰으로 변환 및 BERT 입력 형식으로 변환\ninputs = tokenizer(sentence, return_tensors='pt')\n# BERT 모델을 통해 임베딩 벡터 얻기\nwith torch.no_grad():\n    outputs = model(**inputs)\n# 임베딩 벡터 추출\nembedding_vector = outputs.last_hidden_state.mean(dim=1)",
        "detail": "CH7-AI-Algorithms.embedding-vector.embedding",
        "documentation": {}
    },
    {
        "label": "sentence",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.embedding",
        "description": "CH7-AI-Algorithms.embedding-vector.embedding",
        "peekOfCode": "sentence = \"I love reading books.\"\n# 문장을 토큰으로 변환 및 BERT 입력 형식으로 변환\ninputs = tokenizer(sentence, return_tensors='pt')\n# BERT 모델을 통해 임베딩 벡터 얻기\nwith torch.no_grad():\n    outputs = model(**inputs)\n# 임베딩 벡터 추출\nembedding_vector = outputs.last_hidden_state.mean(dim=1)\nprint(\"임베딩 벡터:\", embedding_vector)",
        "detail": "CH7-AI-Algorithms.embedding-vector.embedding",
        "documentation": {}
    },
    {
        "label": "inputs",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.embedding",
        "description": "CH7-AI-Algorithms.embedding-vector.embedding",
        "peekOfCode": "inputs = tokenizer(sentence, return_tensors='pt')\n# BERT 모델을 통해 임베딩 벡터 얻기\nwith torch.no_grad():\n    outputs = model(**inputs)\n# 임베딩 벡터 추출\nembedding_vector = outputs.last_hidden_state.mean(dim=1)\nprint(\"임베딩 벡터:\", embedding_vector)",
        "detail": "CH7-AI-Algorithms.embedding-vector.embedding",
        "documentation": {}
    },
    {
        "label": "embedding_vector",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.embedding",
        "description": "CH7-AI-Algorithms.embedding-vector.embedding",
        "peekOfCode": "embedding_vector = outputs.last_hidden_state.mean(dim=1)\nprint(\"임베딩 벡터:\", embedding_vector)",
        "detail": "CH7-AI-Algorithms.embedding-vector.embedding",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "def cosine_similarity(vec1, vec2):\n    pass\n    # TODO: 퀴즈 1 정답 입력\n# 임베딩할 단어 리스트\ncategories = ['fruit', 'vehicle', 'animal', 'tool', 'electronic device', 'sport', 'profession', 'emotion', 'planet', 'musical_instrument']\n# BERT 모델 및 토크나이저 불러오기\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n# 단어 임베딩 벡터를 저장할 리스트\nembedding_vectors = []",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "categories",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "categories = ['fruit', 'vehicle', 'animal', 'tool', 'electronic device', 'sport', 'profession', 'emotion', 'planet', 'musical_instrument']\n# BERT 모델 및 토크나이저 불러오기\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n# 단어 임베딩 벡터를 저장할 리스트\nembedding_vectors = []\n# 각 단어를 임베딩 벡터로 변환하고 embedding_vectors에 저장\nfor word in categories:\n    pass\n    # TODO: 퀴즈 2 정답 입력",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n# 단어 임베딩 벡터를 저장할 리스트\nembedding_vectors = []\n# 각 단어를 임베딩 벡터로 변환하고 embedding_vectors에 저장\nfor word in categories:\n    pass\n    # TODO: 퀴즈 2 정답 입력\n# 사용자 입력 받기\nuser_input = input(\"텍스트를 입력하세요: \")",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "model = BertModel.from_pretrained('bert-base-uncased')\n# 단어 임베딩 벡터를 저장할 리스트\nembedding_vectors = []\n# 각 단어를 임베딩 벡터로 변환하고 embedding_vectors에 저장\nfor word in categories:\n    pass\n    # TODO: 퀴즈 2 정답 입력\n# 사용자 입력 받기\nuser_input = input(\"텍스트를 입력하세요: \")\n# 입력된 단어(user_input)를 임베딩 벡터로 변환",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "embedding_vectors",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "embedding_vectors = []\n# 각 단어를 임베딩 벡터로 변환하고 embedding_vectors에 저장\nfor word in categories:\n    pass\n    # TODO: 퀴즈 2 정답 입력\n# 사용자 입력 받기\nuser_input = input(\"텍스트를 입력하세요: \")\n# 입력된 단어(user_input)를 임베딩 벡터로 변환\n# TODO: 여기에 코드를 작성하게요.\n# 코사인 유사도를 통해 입력된 단어와 각 카테고리의 유사도 계산",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "user_input",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "user_input = input(\"텍스트를 입력하세요: \")\n# 입력된 단어(user_input)를 임베딩 벡터로 변환\n# TODO: 여기에 코드를 작성하게요.\n# 코사인 유사도를 통해 입력된 단어와 각 카테고리의 유사도 계산\nsimilarities = []\n# TODO: 여기에 코드를 작성하세요.\n# 유사도가 가장 높은 카테고리 선택\nmax_index = np.argmax(similarities)\npredicted_category = categories[max_index]\n# 결과 출력",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "similarities",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "similarities = []\n# TODO: 여기에 코드를 작성하세요.\n# 유사도가 가장 높은 카테고리 선택\nmax_index = np.argmax(similarities)\npredicted_category = categories[max_index]\n# 결과 출력\nprint(f\"입력한 단어 '{user_input}'는 '{predicted_category}' 카테고리와 가장 유사합니다.\")\nprint('유사도 결과')\nfor i in range(len(categories)):\n    print(f'- {categories[i]}: {similarities[i]}' )",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "max_index",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "max_index = np.argmax(similarities)\npredicted_category = categories[max_index]\n# 결과 출력\nprint(f\"입력한 단어 '{user_input}'는 '{predicted_category}' 카테고리와 가장 유사합니다.\")\nprint('유사도 결과')\nfor i in range(len(categories)):\n    print(f'- {categories[i]}: {similarities[i]}' )",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "predicted_category",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.embedding-vector.quiz",
        "description": "CH7-AI-Algorithms.embedding-vector.quiz",
        "peekOfCode": "predicted_category = categories[max_index]\n# 결과 출력\nprint(f\"입력한 단어 '{user_input}'는 '{predicted_category}' 카테고리와 가장 유사합니다.\")\nprint('유사도 결과')\nfor i in range(len(categories)):\n    print(f'- {categories[i]}: {similarities[i]}' )",
        "detail": "CH7-AI-Algorithms.embedding-vector.quiz",
        "documentation": {}
    },
    {
        "label": "plot_dataset",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.knn.knn",
        "description": "CH7-AI-Algorithms.knn.knn",
        "peekOfCode": "def plot_dataset(X, y):\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\", s=50, edgecolor=\"k\")\n    plt.xlabel(\"Feature 1\")\n    plt.ylabel(\"Feature 2\")\n    plt.title(\"Dataset\")\n    plt.show()\nplot_dataset(X, y)\n# Step 3: Define a function to calculate the Euclidean distance\ndef euclidean_distance(point1, point2):\n    # Implement the Euclidean distance formula",
        "detail": "CH7-AI-Algorithms.knn.knn",
        "documentation": {}
    },
    {
        "label": "euclidean_distance",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.knn.knn",
        "description": "CH7-AI-Algorithms.knn.knn",
        "peekOfCode": "def euclidean_distance(point1, point2):\n    # Implement the Euclidean distance formula\n    return np.sqrt(np.sum((point1 - point2) ** 2))\n# Step 4: Implement the KNN function\ndef knn(X_train, y_train, new_point, k=3):\n    # 1. Calculate distances between new_point and each point in X_train\n    distances = []\n    for i in range(len(X_train)):\n        # Calculate the distance from new_point to X_train[i]\n        dist = euclidean_distance(new_point, X_train[i])",
        "detail": "CH7-AI-Algorithms.knn.knn",
        "documentation": {}
    },
    {
        "label": "knn",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.knn.knn",
        "description": "CH7-AI-Algorithms.knn.knn",
        "peekOfCode": "def knn(X_train, y_train, new_point, k=3):\n    # 1. Calculate distances between new_point and each point in X_train\n    distances = []\n    for i in range(len(X_train)):\n        # Calculate the distance from new_point to X_train[i]\n        dist = euclidean_distance(new_point, X_train[i])\n        distances.append((dist, y_train[i]))  # Save distance and label\n    # 2. Sort distances (ascending) and select the top-k closest neighbors\n    # Sort distances and take the first k neighbors\n    distances.sort(key=lambda x: x[0])",
        "detail": "CH7-AI-Algorithms.knn.knn",
        "documentation": {}
    },
    {
        "label": "plot_knn_steps",
        "kind": 2,
        "importPath": "CH7-AI-Algorithms.knn.knn",
        "description": "CH7-AI-Algorithms.knn.knn",
        "peekOfCode": "def plot_knn_steps(X, y, k, new_point):\n    plt.figure(figsize=(10, 6))\n    # Plot the dataset\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\", s=50, edgecolor=\"k\", label=\"Data points\")\n    # Plot the new point in red\n    plt.scatter(new_point[0], new_point[1], c=\"red\", s=100, label=\"New point\", marker=\"x\")\n    # Find the k nearest neighbors using our KNN function\n    distances = []\n    for i in range(len(X)):\n        dist = euclidean_distance(new_point, X[i])",
        "detail": "CH7-AI-Algorithms.knn.knn",
        "documentation": {}
    },
    {
        "label": "new_point",
        "kind": 5,
        "importPath": "CH7-AI-Algorithms.knn.knn",
        "description": "CH7-AI-Algorithms.knn.knn",
        "peekOfCode": "new_point = [0, -6]\nplot_knn_steps",
        "detail": "CH7-AI-Algorithms.knn.knn",
        "documentation": {}
    }
]